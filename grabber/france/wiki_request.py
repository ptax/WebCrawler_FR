from time import time
import sys
from lib.factory.Loader import Loader
from lib.parser.wiki.France import France as WikiFr
from lib.config.Yaml import Yaml as Config
from lib.factory.Storage import Storage as DocFactory
from lib.logger.File import File as FileLog
from argparse import ArgumentParser


config = Config('./config/config.yml')

arg_parser = ArgumentParser(description='Download data from wiki by link or search request')
arg_parser.add_argument('-f', help='turn on the force mode')
arg_parser.add_argument('-q', help='query for search')
opts = arg_parser.parse_args()

insee_index = 0
name_index = 1
population_index = 2
force_update = opts.f
headers = {'User-Agent': 'Mozilla/5.0'}
loader = Loader.loader_with_mongodb(config.get('mongodb'))
document_factory = DocFactory(config.get('mongodb'))
log = FileLog('./log/wiki_france_{time}.log'.format(time=time()))
log.add('Start', log.INFO)
log.add('Params: [{0}]'.format(repr(opts).encode('utf-8')), log.INFO)

url_format = "https://fr.wikipedia.org/w/index.php?search={0}&title=Sp%C3%A9cial:Recherche&profile=default&fulltext=1&searchengineselect=mediawiki&searchToken=ac9zaxa1lggzxpdhc5ukg06t6"
message_format = 'Parsing request:[{0}]'

use_request = bool(opts.q)
custom_request = opts.q if use_request else ''

def update_meta(url, request, document):
    actual_doc = document.get_document()
    actual_doc.update(url=url)
    added_requests = actual_doc.get('requests', []) + [request]
    actual_doc.update(requests=list(set(added_requests)))
    document.update(actual_doc)

try:
    if use_request:
        url = url_format.format(custom_request)
        log.add(message_format.format(custom_request), log.INFO)
        content, code = loader.load(url, headers=headers)
        parser = WikiFr(content)

        if parser.is_many_answers():
            urls = parser.get_answers_links()
            for answer_url in urls:
                doc = document_factory.wiki(answer_url)
                if doc.is_new() or force_update:
                    page, code = loader.load(answer_url, headers=headers)
                    page_parser = WikiFr(page)
                    if page_parser.is_location_page():
                        doc.update(page_parser.as_dictionary())
                update_meta(url=answer_url, request=url, document=doc)
        elif parser.is_location_page():
            doc = document_factory.wiki(url)
            if doc.is_new() or force_update:
                doc.update(parser.as_dictionary())
            update_meta(url=url, request=url, document=doc)
    else:
        log.add('Wrong command', log.ERROR)
        print('use parameters like -s csv file or -r query string or -l link to wiki page')
except:
    message = str(sys.exc_info())
    log.add('Unexpected error: [{0}]'.format(message), log.ERROR)
    raise

log.add('Finish', log.INFO)